# network architecture
model-module: espnet.nets.pytorch_backend.e2e_asr_transducer_mix:E2E
# encoder related
etype: vggblstmp
elayers-sd: 1   # number of speaker differentiate encoder layers
elayers: 2      # number of recognition encoder layers
eunits: 1024
eprojs: 1024
subsample: 1_2_2_1_1  # skip every n frame from input to nth layers

# decoder related
dtype: lstm
dlayers: 1
dec-embed-dim: 256
dunits: 256
dropout-rate-decoder: 0.2
dropout-rate-embed-decoder: 0.2

# attention related
atype: location
adim: 320
awin: 5
aheads: 4
aconv-chans: 10
aconv-filts: 100

# transducer related
# use RNN-Transducer instead of CTC
aligner: 'rnnt'
rnnt-mode: 'rnnt'

# hybrid system will not work with RNNT
mtlalpha: 1

# label smoothing
lsm-type: unigram
lsm-weight: 0.05

# minibatch related
batch-size: 2
maxlen-in: 1000  # if input length  > maxlen-in, batchsize is automatically reduced
maxlen-out: 150 # if output length > maxlen-out, batchsize is automatically reduced

# optimization related
sortagrad: 0 # Feed samples from shortest to longest ; -1: enabled for all epochs, 0: disabled, other: enabled for 'other' epochs
opt: adadelta
accum-grad: 1
grad-clip: 5
patience: 3
epochs: 15
dropout-rate: 0.0

# scheduled sampling option
sampling-probability: 0.0
